{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DWM10_Parms\n",
    "from collections import OrderedDict\n",
    "from textdistance import DamerauLevenshtein\n",
    "#from textdistance import Levenshtein\n",
    "import Levenshtein as lev\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globalReplace(refDict, tokenFreqDict):\n",
    "    logFile = DWM10_Parms.logFile\n",
    "    print (\"\\n>>Starting DWM25 --- runGlobalCorrection is set to True\")\n",
    "    print(\"\\n>>Starting DWM25 --- runGlobalCorrection is set to True\", file=logFile)\n",
    "    Class = DamerauLevenshtein()\n",
    "#Phase 1 Create Dictionary from DWM_WordList\n",
    "    wordListDict = {}\n",
    "    wordListFile = open('DWM_WordList.txt','r')\n",
    "    word = wordListFile.readline().strip()\n",
    "    itemsRead = 1\n",
    "    while word != '':\n",
    "        wordListDict.update({word:''})\n",
    "        word = wordListFile.readline().strip()\n",
    "        itemsRead +=1\n",
    "    wordListFile.close()\n",
    "    print('Items read =', itemsRead)\n",
    "    print('wordListDict size =', len(wordListDict))\n",
    "    minFreqStdToken = DWM10_Parms.minFreqStdToken\n",
    "    minLenStdToken = DWM10_Parms.minLenStdToken\n",
    "    maxFreqErrToken = DWM10_Parms.maxFreqErrToken\n",
    "    print(\"DWM_WordList loaded, word count = \", len(wordListDict))\n",
    "    print(\"DWM_WordList loaded, word count = \", len(wordListDict), file=logFile)\n",
    "    print(\"Minimum Frequency of Standard Token = \", minFreqStdToken)\n",
    "    print(\"Minimum Frequency of Standard Token = \", minFreqStdToken, file=logFile)   \n",
    "    print(\"Minimum Length of Standard Token = \", minLenStdToken)\n",
    "    print(\"Minimum Length of Standard Token = \", minLenStdToken, file=logFile)   \n",
    "    print(\"Maximum Frequency of Error Token = \", maxFreqErrToken)\n",
    "    print(\"Maximum Frequency of Error Token = \", maxFreqErrToken, file=logFile)\n",
    "#Phase 2, build list of token-frequency pairs and sort descending by token frequency\n",
    "    print('tokenFreqDict size = ', len(tokenFreqDict))\n",
    "    print('tokenFreqDict size = ', len(tokenFreqDict), file=logFile)\n",
    "    sortedIndex = sorted(tokenFreqDict.items(),reverse=True, key=operator.itemgetter(1))\n",
    "    tokenCnt = len(sortedIndex)\n",
    "    print(\"Sorted Token Size =\", tokenCnt)\n",
    "    print(\"Sorted Token Size =\", tokenCnt, file=logFile)\n",
    "    cleanIndex = []\n",
    "    for j in range(0,tokenCnt):\n",
    "        pairJ = sortedIndex[j]\n",
    "        wordJ = pairJ[0]\n",
    "        lenJ = len(wordJ)\n",
    "        freqJ = pairJ[1]\n",
    "        if lenJ<minLenStdToken:\n",
    "            continue\n",
    "        if not wordJ.isalpha():\n",
    "            continue\n",
    "        if (freqJ<=maxFreqErrToken) and (wordJ in wordListDict):\n",
    "            continue        \n",
    "        cleanIndex.append(pairJ)\n",
    "    cleanCnt = len(cleanIndex)\n",
    "    print(\"Clean Token Size =\", cleanCnt)\n",
    "    print(\"Clean Token Size =\", cleanCnt, file=logFile)\n",
    "#Phase 3 Populate Dictionary (stdTokenDict) of token corrections\n",
    "    stdTokenDict = {}\n",
    "    checkCnt = 0\n",
    "    for j in range(0,cleanCnt-1):\n",
    "        pairJ = cleanIndex[j]\n",
    "        wordJ = pairJ[0]\n",
    "        lenJ = len(wordJ)\n",
    "        freqJ = pairJ[1]\n",
    "        if freqJ < minFreqStdToken:\n",
    "            break\n",
    "        for k in range(cleanCnt-1, 1, -1):\n",
    "            pairK = cleanIndex[k]\n",
    "            wordK = pairK[0]\n",
    "            lenK = len(wordK)\n",
    "            freqK = pairK[1]\n",
    "            if freqK > maxFreqErrToken:\n",
    "                break\n",
    "            dis = lev.distance(wordJ.lower(),wordK.lower())     \n",
    "            if dis == 1:\n",
    "                stdTokenDict[wordK] = wordJ\n",
    "                cleanIndex[k] = ('',freqK)                   \n",
    "            elif dis == 2:\n",
    "                if Class.distance(wordJ,wordK)==1:\n",
    "                    stdTokenDict[wordK] = wordJ\n",
    "                    cleanIndex[k] = ('',freqK)\n",
    "    print('\\nTotal correction pairs = ', len(stdTokenDict)) \n",
    "    print('\\nTotal correction pairs = ', len(stdTokenDict), file=logFile) \n",
    "    # If detail requested, write changes to run log\n",
    "    if DWM10_Parms.globalCorrectionDetail:\n",
    "        print('Details of correction sent to logFile')\n",
    "        print('Error Token, Correction Token', file=logFile)\n",
    "        for token in stdTokenDict:\n",
    "            print(token+','+stdTokenDict[token], file=logFile)\n",
    "    # Apply corrections to all references\n",
    "    newList = []\n",
    "    newDict = {}\n",
    "    tokenChangeCnt = 0\n",
    "    refChangeCnt = 0\n",
    "    for refID in refDict:\n",
    "        tokenList = refDict[refID]\n",
    "        #print('**ref=',refID, 'before', tokenList)\n",
    "        changeMade = False\n",
    "        newList = []\n",
    "        change = False\n",
    "        for token in tokenList:\n",
    "            if token in stdTokenDict:\n",
    "                newList.append(stdTokenDict[token])\n",
    "                tokenChangeCnt +=1\n",
    "                change = True\n",
    "            else:\n",
    "                newList.append(token)\n",
    "        newDict[refID] = newList\n",
    "        if change:\n",
    "            refChangeCnt +=1\n",
    "    print('Total tokens corrected = ', tokenChangeCnt) \n",
    "    print('Total tokens corrected = ', tokenChangeCnt, file=logFile)\n",
    "    print('Total references corrected = ', refChangeCnt) \n",
    "    print('Total references corrected = ', refChangeCnt, file=logFile)\n",
    "    return newDict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
