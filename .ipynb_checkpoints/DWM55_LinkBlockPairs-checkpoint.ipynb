{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from textdistance import Cosine\n",
    "from textdistance import MongeElkan\n",
    "import DWM10_Parms\n",
    "import DWM65_ScoringMatrixStd\n",
    "import DWM66_ScoringMatrixKris\n",
    "def linkBlockPairs(blockPairList, refDict, tokenFreqDict): \n",
    "    logFile = DWM10_Parms.logFile\n",
    "    sigma = DWM10_Parms.sigma\n",
    "    removeDuplicateTokens = DWM10_Parms.removeDuplicateTokens\n",
    "    removeExcludedBlkTokens = DWM10_Parms.removeExcludedBlkTokens\n",
    "    minBlkTokenLen = DWM10_Parms.minBlkTokenLen\n",
    "    excludeNumericBlocks = DWM10_Parms.excludeNumericBlocks\n",
    "    print('\\n>>Starting DWM55')\n",
    "    print('\\n>>Starting DWM55', file=logFile)\n",
    "    print('Sigma =', sigma)\n",
    "    print('Sigma =', sigma, file=logFile)    \n",
    "    print('Remove Duplicate Tokens =', removeDuplicateTokens)\n",
    "    print('Remove Duplicate Tokens =', removeDuplicateTokens, file=logFile)\n",
    "    print('Remove Excluded Block Tokens =', removeExcludedBlkTokens)\n",
    "    print('Remove Excluded Block Tokens =', removeExcludedBlkTokens, file=logFile)\n",
    "    # Define nested function for removing stop words\n",
    "    def removeStopWords(tokenList):\n",
    "        newList = []\n",
    "        #print('-- tokenList', tokenList)\n",
    "        for token in tokenList:\n",
    "            tokenLen = len(token)\n",
    "            includeToken = True\n",
    "            freq = tokenFreqDict[token]\n",
    "            if freq>=sigma:\n",
    "                includeToken = False\n",
    "                #print('-- sigma rule', token, freq)\n",
    "            if removeExcludedBlkTokens:\n",
    "                if tokenLen < minBlkTokenLen:\n",
    "                    includeToken = False\n",
    "                    #print('-- min len rule', token, tokenLen)\n",
    "                if token.isdigit() and excludeNumericBlocks:\n",
    "                    includeToken = False\n",
    "                    #print('-- number rule', token)\n",
    "            if removeDuplicateTokens and (token in newList):\n",
    "                includeToken = False\n",
    "                #print('-- duplicate token rule', token)\n",
    "            if includeToken:\n",
    "                newList.append(token)\n",
    "       # print('-- newList', newList)\n",
    "        return newList\n",
    "    # end of nexted fucntion\n",
    "    # Check for valid comparator\n",
    "    validComparator = False\n",
    "    comparator = DWM10_Parms.comparator\n",
    "    if comparator == 'MongeElkan':\n",
    "        Class = MongeElkan()\n",
    "        validComparator = True\n",
    "    if comparator == 'Cosine':\n",
    "        Class = Cosine()\n",
    "        validComparator = True\n",
    "    if comparator == 'ScoringMatrixStd':\n",
    "        Class = DWM65_ScoringMatrixStd\n",
    "        validComparator = True\n",
    "    if comparator == 'ScoringMatrixKris':\n",
    "        Class = DWM66_ScoringMatrixKris\n",
    "        validComparator = True        \n",
    "    if not validComparator:\n",
    "        print('**Error: Invalid Comparator Value in Parms File', comparator)\n",
    "        sys.exit()\n",
    "    mu = DWM10_Parms.mu\n",
    "    linkedPairList = []\n",
    "    blockPairListLen = len(blockPairList)\n",
    "    for j in range(0, blockPairListLen):\n",
    "        pair = blockPairList[j]\n",
    "        refIDs = pair.split('|')\n",
    "        refID1 = refIDs[0]\n",
    "        refID2 = refIDs[1]\n",
    "        tokenList1 = removeStopWords(refDict[refID1])\n",
    "        tokenList2 = removeStopWords(refDict[refID2])\n",
    "        result = Class.normalized_similarity(tokenList1[:],tokenList2[:])\n",
    "        if result >= mu:\n",
    "            linkedPairList.append((refID1,refID2))\n",
    "    print('Number of Pairs Linked =', len(linkedPairList), 'at mu=', mu)\n",
    "    print('Number of Pairs Linked =', len(linkedPairList), 'at mu=', mu, file=logFile)\n",
    "    return linkedPairList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
